{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is a notebook to train TRPO agent in CatGym environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env MKL_NUM_THREADS=1\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env NUMEXPR_NUM_THREADS=1\n",
    "%env MKL_DEBUG_CPU_TYPE=5"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: MKL_NUM_THREADS=1\n",
      "env: OMP_NUM_THREADS=1\n",
      "env: NUMEXPR_NUM_THREADS=1\n",
      "env: MKL_DEBUG_CPU_TYPE=5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "seed = 30\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up the environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import gym\n",
    "from surface_seg.envs.catgym_env import MCSEnv\n",
    "from surface_seg.utils.callback_new import Callback\n",
    "from tensorforce.execution import Runner\n",
    "import gym.wrappers\n",
    "import numpy as np\n",
    "import tensorforce\n",
    "import copy\n",
    "import os, json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "timesteps = 500\n",
    "# Substitute your own directory for saving result during training\n",
    "save_dir = './result_multi_env/test_catgym'\n",
    "num_parallel = 32\n",
    "thermal_threshold = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def setup_env(recording=True, structure=None, structure_idx=None):\n",
    "    \n",
    "    # Set up gym\n",
    "    MCS_gym = MCSEnv(observation_fingerprints=True, \n",
    "                     observation_forces=True,\n",
    "                     permute_seed=42, \n",
    "                     save_dir = save_dir,\n",
    "                     timesteps = timesteps,\n",
    "                     thermal_threshold = thermal_threshold,\n",
    "                     save_every_min = 1,\n",
    "                     save_every = 50,\n",
    "                     step_size = 0.1,                    \n",
    "                    )\n",
    "    \n",
    "    if recording:\n",
    "    # Wrap the gym to provide video rendering every 50 steps\n",
    "        MCS_gym = gym.wrappers.Monitor(MCS_gym, \n",
    "                                         os.path.join(save_dir, 'vid'), \n",
    "                                         force=True,\n",
    "                                        video_callable = lambda episode_id: (episode_id+1)%50==0) #every 50, starting at 51\n",
    "    \n",
    "    #Convert gym to tensorforce environment\n",
    "    env = tensorforce.environments.OpenAIGym(MCS_gym,\n",
    "                                         max_episode_timesteps=timesteps,\n",
    "                                         visualize=False)\n",
    "    \n",
    "    return env\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create a environment for checking the intial energy and thermal energy\n",
    "\"\"\"\n",
    "env = setup_env().environment.env\n",
    "print('initial energy', env.initial_energy)\n",
    "print('thermal energy', env.thermal_energy)\n",
    "n =thermal_threshold\n",
    "print('%dKT' %n, n * env.thermal_energy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "initial energy 4.094021275192408\n",
      "thermal energy 0.827232\n",
      "3KT 2.481696\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up the agent in tensorforce"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from tensorforce.agents import Agent\n",
    "tf.random.set_seed(seed)\n",
    "agent = Agent.create(\n",
    "    agent=dict(type='trpo'),\n",
    "    environment=setup_env(recording=False), \n",
    "    batch_size=1,\n",
    "    learning_rate=1e-3,\n",
    "    memory = 50000,\n",
    "    max_episode_timesteps = timesteps,\n",
    "    exploration=dict(\n",
    "        type='decaying', unit='timesteps', decay='exponential',\n",
    "        initial_value=0.2, decay_steps=50000, decay_rate=0.5 #10000, 50000, 1000000\n",
    "    ),\n",
    "    parallel_interactions = num_parallel,\n",
    ")\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorforce/core/module.py:701: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./result_multi_env/experiments/test_catgym/checkpoints/agent.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Check agent specifications\n",
    "print(agent.spec)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OrderedDict([('agent', 'trpo'), ('states', {'TS': {'type': 'float', 'shape': (1,)}, 'energy': {'type': 'float', 'shape': (1,)}, 'fingerprints': {'type': 'float', 'shape': (192,)}, 'forces': {'type': 'float', 'shape': (24,)}, 'positions': {'type': 'float', 'shape': (24,)}}), ('actions', {'action_type': {'type': 'int', 'shape': (), 'num_values': 4}, 'atom_selection': {'type': 'int', 'shape': (), 'num_values': 8}, 'movement': {'type': 'float', 'shape': (1, 3), 'min_value': -0.10000000149011612, 'max_value': 0.10000000149011612}}), ('max_episode_timesteps', 500), ('batch_size', 1), ('network', 'auto'), ('use_beta_distribution', True), ('memory', 50000), ('update_frequency', None), ('learning_rate', 0.001), ('discount', 0.99), ('estimate_terminal', False), ('critic_network', None), ('critic_optimizer', None), ('preprocessing', None), ('exploration', {'type': 'decaying', 'unit': 'timesteps', 'decay': 'exponential', 'initial_value': 0.2, 'decay_steps': 50000, 'decay_rate': 0.5}), ('variable_noise', 0.0), ('l2_regularization', 0.0), ('entropy_regularization', 0.0), ('name', 'agent'), ('device', None), ('parallel_interactions', 32), ('seed', None), ('execution', None), ('saver', {'directory': './result_multi_env/experiments/test_catgym/checkpoints', 'frequency': 600}), ('summarizer', None), ('recorder', None), ('config', None)])\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the DRL method in parallel (multiple environments)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "num_episode = num_parallel*300\n",
    "\n",
    "callback = Callback(num_episode, save_dir).episode_finish\n",
    "\n",
    "runner = Runner( \n",
    "    agent=agent,\n",
    "    environments=[setup_env(recording=False) for _ in range(num_parallel)],\n",
    "    num_parallel=num_parallel,\n",
    "    remote='multiprocessing',\n",
    "    max_episode_timesteps=timesteps,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Multi-env training does not close after being trained for specified num_episodes.\n",
    "Manual termination required.\n",
    "\"\"\"\n",
    "runner.run(num_episodes=num_episode, callback=callback, callback_episode_frequency=1)\n",
    "runner.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Episodes: 100%|██████████| 20/20 [01:41, reward=-2.46, ts/ep=312, sec/ep=101.63, ms/ts=325.7, agent=1.4%, comm=30.9%]\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the DRL method in single environment (use when parallel not available)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# num_episode = 300\n",
    "# callback = Callback(num_episode, save_dir).episode_finish\n",
    "\n",
    "# runner = Runner( \n",
    "#     agent=agent,\n",
    "#     environment=setup_env(recording=False),\n",
    "#     max_episode_timesteps=timesteps,\n",
    "# )\n",
    "\n",
    "# runner.run(num_episodes=num_episode, callback=callback, callback_episode_frequency=1)\n",
    "# runner.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save the trained agent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorforce.agents.agent import TensorforceJSONEncoder\n",
    "from collections import OrderedDict\n",
    "\n",
    "save_agent_dir = os.path.join(save_dir, 'saved_agent')\n",
    "agent_name = 'agent'\n",
    "\n",
    "agent.model.save(directory=save_agent_dir, filename=agent_name, format='tensorflow', append=None)\n",
    "spec_path = os.path.join(save_agent_dir, agent_name + '.json')\n",
    "try:\n",
    "    with open(spec_path, 'w') as fp:\n",
    "        spec = OrderedDict(agent.spec)\n",
    "        spec['internals'] = agent.internals_spec\n",
    "        spec['initial_internals'] = agent.initial_internals()\n",
    "        json.dump(obj=spec, fp=fp, cls=TensorforceJSONEncoder)\n",
    "except BaseException:\n",
    "    try:\n",
    "        with open(spec_path, 'w') as fp:\n",
    "            spec = OrderedDict()\n",
    "            spec['states'] = agent.spec['states']\n",
    "            spec['actions'] = agent.spec['actions']\n",
    "            spec['internals'] = agent.internals_spec\n",
    "            spec['initial_internals'] = agent.initial_internals()\n",
    "            json.dump(obj=spec, fp=fp, cls=TensorforceJSONEncoder)\n",
    "    except BaseException:\n",
    "        os.remove(spec_path)\n",
    "        print('Agent saving failed')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}