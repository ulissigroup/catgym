{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=1\n",
    "# %env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load intel ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the gym and wrap a monitor around it that will periodically record movies as it learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from surface_seg.envs.mcs_env import MCSEnv\n",
    "import gym.wrappers\n",
    "import numpy as np\n",
    "import tensorforce \n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_env():\n",
    "    \n",
    "    Gs = {}\n",
    "    Gs[\"G2_etas\"] = np.logspace(np.log10(0.05), np.log10(5.0), num=4)\n",
    "    Gs[\"G2_rs_s\"] = [0] * 4\n",
    "    Gs[\"G4_etas\"] = [0.005]\n",
    "    Gs[\"G4_zetas\"] = [1.0]\n",
    "    Gs[\"G4_gammas\"] = [+1.0, -1]\n",
    "    Gs[\"cutoff\"] = 6.5\n",
    "\n",
    "    G = copy.deepcopy(Gs)\n",
    "\n",
    "    # order descriptors for simple_nn\n",
    "    cutoff = G[\"cutoff\"]\n",
    "    G[\"G2_etas\"] = [a / cutoff**2 for a in G[\"G2_etas\"]]\n",
    "    G[\"G4_etas\"] = [a / cutoff**2 for a in G[\"G4_etas\"]]\n",
    "    descriptors = (\n",
    "        G[\"G2_etas\"],\n",
    "        G[\"G2_rs_s\"],\n",
    "        G[\"G4_etas\"],\n",
    "        G[\"cutoff\"],\n",
    "        G[\"G4_zetas\"],\n",
    "        G[\"G4_gammas\"],\n",
    "    )\n",
    "    \n",
    "    # Set up gym\n",
    "    MCS_gym = MCSEnv(fingerprints=True, descriptors=descriptors)\n",
    "    \n",
    "    # Wrap the gym to provide video rendering every 50 steps\n",
    "    recording_MCS_gym = gym.wrappers.Monitor(MCS_gym, \n",
    "                                         \"./vid\", \n",
    "                                         force=True,\n",
    "                                        video_callable = lambda episode_id: (episode_id+1)%50==0)\n",
    "    \n",
    "    #Convert gym to tensorfce environment\n",
    "    recording_env = tensorforce.environments.OpenAIGym(recording_MCS_gym,\n",
    "                                         max_episode_timesteps=400,\n",
    "                                         visualize=False)\n",
    "    \n",
    "    return recording_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the gym and agent in tensorforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/homes/z/zulissi/miniconda3/envs/surface_seg/lib/python3.8/site-packages/tensorflow-2.2.0-py3.8-linux-x86_64.egg/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /global/homes/z/zulissi/miniconda3/envs/surface_seg/lib/python3.8/site-packages/Tensorforce-0.5.4-py3.8.egg/tensorforce/core/module.py:656: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "from tensorforce.agents import Agent\n",
    "\n",
    "agent = Agent.create(\n",
    "    agent='trpo', \n",
    "    environment=setup_env(), \n",
    "    batch_size=10, \n",
    "    learning_rate=1e-2,\n",
    "    memory = 40000,\n",
    "    max_episode_timesteps = 400,\n",
    "    exploration=dict(\n",
    "        type='decaying', unit='timesteps', decay='exponential',\n",
    "        initial_value=0.3, decay_steps=1000, decay_rate=0.5\n",
    "    ))\n",
    "\n",
    "agent_spec = agent.spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the DRL method on a single instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 0/1000 [00:00, reward=0.00, ts/ep=0, sec/ep=0.00, ms/ts=0.0, agent=0.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.16 w energy 0.20\n",
      "found a new local minima! distance=2.26 w energy -0.03\n",
      "found a new local minima! distance=3.27 w energy 1.28\n",
      "found a new local minima! distance=2.34 w energy 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 1/1000 [00:32, reward=3991.12, ts/ep=400, sec/ep=32.05, ms/ts=80.1, agent=33.7%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.18 w energy -0.01\n",
      "found a new local minima! distance=1.45 w energy 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 2/1000 [00:46, reward=1963.62, ts/ep=400, sec/ep=14.75, ms/ts=36.9, agent=10.1%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.59 w energy 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 3/1000 [01:03, reward=1320.30, ts/ep=400, sec/ep=16.71, ms/ts=41.8, agent=8.7%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.00 w energy 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 4/1000 [01:14, reward=1953.38, ts/ep=400, sec/ep=10.68, ms/ts=26.7, agent=14.2%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.91 w energy 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 5/1000 [01:25, reward=1943.49, ts/ep=400, sec/ep=11.79, ms/ts=29.5, agent=12.2%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 6/1000 [01:34, reward=3042.52, ts/ep=400, sec/ep=8.63, ms/ts=21.6, agent=16.7%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 7/1000 [01:43, reward=3035.34, ts/ep=400, sec/ep=8.38, ms/ts=20.9, agent=16.8%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.43 w energy 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 8/1000 [01:50, reward=2046.25, ts/ep=400, sec/ep=7.77, ms/ts=19.4, agent=18.4%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 9/1000 [01:58, reward=3027.28, ts/ep=400, sec/ep=7.99, ms/ts=20.0, agent=18.1%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 10/1000 [02:07, reward=3030.47, ts/ep=400, sec/ep=8.84, ms/ts=22.1, agent=16.2%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.07 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 11/1000 [02:20, reward=1976.87, ts/ep=400, sec/ep=13.14, ms/ts=32.9, agent=47.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.18 w energy -0.01\n",
      "found a new local minima! distance=1.45 w energy 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 12/1000 [02:29, reward=2038.95, ts/ep=400, sec/ep=8.67, ms/ts=21.7, agent=16.1%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.15 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|▏         | 13/1000 [02:37, reward=1980.04, ts/ep=400, sec/ep=7.80, ms/ts=19.5, agent=19.2%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|▏         | 14/1000 [02:45, reward=3068.53, ts/ep=400, sec/ep=8.00, ms/ts=20.0, agent=17.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.32 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 15/1000 [02:53, reward=3048.39, ts/ep=400, sec/ep=7.94, ms/ts=19.8, agent=19.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 16/1000 [03:00, reward=3047.02, ts/ep=400, sec/ep=7.79, ms/ts=19.5, agent=18.9%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 17/1000 [03:08, reward=3049.43, ts/ep=400, sec/ep=8.01, ms/ts=20.0, agent=19.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 18/1000 [03:16, reward=3039.55, ts/ep=400, sec/ep=7.44, ms/ts=18.6, agent=19.6%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 19/1000 [03:23, reward=3037.79, ts/ep=400, sec/ep=7.55, ms/ts=18.9, agent=18.5%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 20/1000 [03:31, reward=3051.18, ts/ep=400, sec/ep=7.84, ms/ts=19.6, agent=18.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 21/1000 [03:45, reward=3051.59, ts/ep=400, sec/ep=13.34, ms/ts=33.3, agent=46.6%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.17 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 22/1000 [03:52, reward=1989.74, ts/ep=400, sec/ep=7.49, ms/ts=18.7, agent=18.3%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 23/1000 [04:00, reward=3050.46, ts/ep=400, sec/ep=7.53, ms/ts=18.8, agent=18.4%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 24/1000 [04:08, reward=3045.59, ts/ep=400, sec/ep=8.17, ms/ts=20.4, agent=17.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▎         | 25/1000 [04:15, reward=3044.22, ts/ep=400, sec/ep=7.53, ms/ts=18.8, agent=19.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.04 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 26/1000 [04:23, reward=1981.36, ts/ep=400, sec/ep=7.52, ms/ts=18.8, agent=18.4%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 27/1000 [04:31, reward=3056.07, ts/ep=400, sec/ep=7.96, ms/ts=19.9, agent=18.5%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.12 w energy -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 28/1000 [04:37, reward=1092.89, ts/ep=400, sec/ep=6.09, ms/ts=15.2, agent=23.5%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 29/1000 [04:45, reward=3041.51, ts/ep=400, sec/ep=7.65, ms/ts=19.1, agent=19.1%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 30/1000 [04:52, reward=3037.25, ts/ep=400, sec/ep=7.59, ms/ts=19.0, agent=18.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 31/1000 [05:04, reward=3046.79, ts/ep=400, sec/ep=12.25, ms/ts=30.6, agent=49.6%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 32/1000 [05:13, reward=3053.10, ts/ep=400, sec/ep=8.28, ms/ts=20.7, agent=16.4%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 33/1000 [05:20, reward=3040.07, ts/ep=400, sec/ep=7.65, ms/ts=19.1, agent=19.1%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 34/1000 [05:28, reward=3047.82, ts/ep=400, sec/ep=7.81, ms/ts=19.5, agent=18.6%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▎         | 35/1000 [05:36, reward=3056.56, ts/ep=400, sec/ep=8.18, ms/ts=20.4, agent=18.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▎         | 36/1000 [05:44, reward=3043.82, ts/ep=400, sec/ep=7.79, ms/ts=19.5, agent=18.8%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.17 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▎         | 37/1000 [05:52, reward=1987.05, ts/ep=400, sec/ep=7.68, ms/ts=19.2, agent=18.1%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 38/1000 [05:59, reward=3043.59, ts/ep=400, sec/ep=7.62, ms/ts=19.1, agent=18.8%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 39/1000 [06:07, reward=3039.07, ts/ep=400, sec/ep=7.45, ms/ts=18.6, agent=18.7%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 40/1000 [06:15, reward=3043.94, ts/ep=400, sec/ep=8.07, ms/ts=20.2, agent=18.1%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 41/1000 [06:27, reward=3042.50, ts/ep=400, sec/ep=12.50, ms/ts=31.2, agent=50.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 42/1000 [06:35, reward=3037.79, ts/ep=400, sec/ep=7.58, ms/ts=19.0, agent=19.0%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 43/1000 [06:43, reward=3043.55, ts/ep=400, sec/ep=7.48, ms/ts=18.7, agent=18.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 44/1000 [06:51, reward=3051.77, ts/ep=400, sec/ep=8.32, ms/ts=20.8, agent=16.4%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.17 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 45/1000 [06:59, reward=1984.23, ts/ep=400, sec/ep=7.87, ms/ts=19.7, agent=18.1%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   5%|▍         | 46/1000 [07:06, reward=3038.03, ts/ep=400, sec/ep=7.46, ms/ts=18.6, agent=18.9%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=2.17 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   5%|▍         | 47/1000 [07:15, reward=1994.70, ts/ep=400, sec/ep=8.44, ms/ts=21.1, agent=18.3%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   5%|▍         | 48/1000 [07:22, reward=3039.66, ts/ep=400, sec/ep=7.59, ms/ts=19.0, agent=19.4%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new local minima! distance=0.08 w energy -0.01\n",
      "found a new local minima! distance=1.81 w energy 0.19\n",
      "found a new local minima! distance=0.36 w energy 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   5%|▍         | 49/1000 [07:30, reward=3052.35, ts/ep=400, sec/ep=8.02, ms/ts=20.1, agent=18.0%]"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2d67cd25cc22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/Tensorforce-0.5.4-py3.8.egg/tensorforce/execution/runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_episodes, num_timesteps, num_updates, batch_agent_calls, sync_timesteps, sync_episodes, num_sleep_secs, callback, callback_episode_frequency, callback_timestep_frequency, use_tqdm, mean_horizon, evaluation, save_best_agent, evaluation_callback)\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                     \u001b[0;31m# Check whether environment is ready, otherwise continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mobservation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_terminals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/Tensorforce-0.5.4-py3.8.egg/tensorforce/environments/environment.py\u001b[0m in \u001b[0;36mreceive_execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expect_receive\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reset'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expect_receive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expect_receive\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'execute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/Tensorforce-0.5.4-py3.8.egg/tensorforce/environments/environment.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/Tensorforce-0.5.4-py3.8.egg/tensorforce/environments/openai_gym.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIGym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/gym-0.17.2-py3.8.egg/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/gym-0.17.2-py3.8.egg/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_after_reset\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/gym-0.17.2-py3.8.egg/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/gym-0.17.2-py3.8.egg/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_ansi_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_image_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/gym-0.17.2-py3.8.egg/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36m_encode_image_frame\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode_image_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes_per_sec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_frames_per_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/surface_seg/lib/python3.8/site-packages/gym-0.17.2-py3.8.egg/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_path, frame_shape, frames_per_sec, output_frames_per_sec)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ffmpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDependencyNotInstalled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`."
     ]
    }
   ],
   "source": [
    "from tensorforce.execution import Runner\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent_spec,\n",
    "    environment=setup_env(),\n",
    "    max_episode_timesteps=400,\n",
    ")\n",
    "\n",
    "runner.run(num_episodes=1000)\n",
    "runner.run(num_episodes=100, evaluation=True)\n",
    "runner.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the DRL method in parallel (multiple environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorforce.execution import Runner\n",
    "\n",
    "# runner = Runner(\n",
    "#     agent=agent_spec,\n",
    "#     environments=[setup_env(), setup_env()],\n",
    "#     num_parallel=2,\n",
    "#     max_episode_timesteps=400,\n",
    "# )\n",
    "\n",
    "# runner.run(num_episodes=1000)\n",
    "# runner.run(num_episodes=100, evaluation=True)\n",
    "# runner.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to render the environment in a jupyter cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MCS_gym\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "plt.axis('off')\n",
    "for _ in range(100):\n",
    "    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:surface_seg]",
   "language": "python",
   "name": "conda-env-surface_seg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
